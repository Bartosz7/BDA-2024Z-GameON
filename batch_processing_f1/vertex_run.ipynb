{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import (\n",
    "    component, \n",
    "    Output,\n",
    "    Input,\n",
    "    Model\n",
    ")\n",
    "\n",
    "from kfp import compiler\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = \"europe-west3-docker.pkg.dev/bda-gameon-demo/vertex/base_f1_container:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def load_and_preprocess(\n",
    "    current_year: int,\n",
    "    race_id: int,\n",
    "):\n",
    "    import requests\n",
    "    from vertex_utils import (\n",
    "        prepare_df_from_json,\n",
    "        prepare_aggregations,\n",
    "        enrich_with_drivers,\n",
    "        enrich_with_races,\n",
    "        save_historic_to_big_query\n",
    "    )\n",
    "    \n",
    "    API_BASE_URL = \"https://big-data-project-api-248863766350.europe-west3.run.app/laps\"\n",
    "    api_url = f\"{API_BASE_URL}/{race_id}\"\n",
    "    response = requests.get(api_url)\n",
    "    data = response.json()\n",
    "\n",
    "    print(f\"Gathering data for race: {race_id}...\")\n",
    "    df = prepare_df_from_json(data)\n",
    "\n",
    "    print(\"Preparing aggregations...\")\n",
    "    aggregations = prepare_aggregations(df)\n",
    "\n",
    "    print(\"Adding information from drivers table...\")\n",
    "    aggregations = enrich_with_drivers(aggregations, current_year)\n",
    "    \n",
    "    print(\"Adding information from races table...\")\n",
    "    aggregations = enrich_with_races(aggregations)\n",
    "\n",
    "    aggregations = aggregations.drop([\"driverId\", \"raceId\", \"race_id\", \"milliseconds\"], axis=1)\n",
    "\n",
    "    print(\"Saving aggregations to BigQuery...\")\n",
    "    save_historic_to_big_query(aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def train_model(trained_model: Output[Model]):\n",
    "    from xgboost import XGBRegressor\n",
    "    import joblib\n",
    "    import os\n",
    "\n",
    "    from vertex_utils import load_historic\n",
    "    \n",
    "    final_df = load_historic()\n",
    "\n",
    "    X = final_df.drop(columns=['final_position'])\n",
    "    y = final_df['final_position']\n",
    "\n",
    "    xgb_model = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X, y)\n",
    "\n",
    "    model_dir = trained_model.path\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir) \n",
    "\n",
    "    model_path = model_dir + \"/model.joblib\"\n",
    "    joblib.dump(xgb_model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def deploy_model(trained_model: Input[Model]):\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    project = \"bda-gameon-demo\"\n",
    "    endpoint_name = \"f1_model_endpoint\"\n",
    "    region = \"europe-west3\"\n",
    "    \n",
    "    aiplatform.init(project=project, location=region)\n",
    "\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name=\"f1_model\",\n",
    "        artifact_uri=trained_model.uri,\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-5:latest\",\n",
    "    )\n",
    "    print(f\"Model registered with resource name: {model.resource_name}\")\n",
    "\n",
    "    # endpoint = aiplatform.Endpoint.create(display_name=endpoint_name)\n",
    "    # model.deploy(\n",
    "    #     endpoint=endpoint,\n",
    "    #     deployed_model_display_name=\"f1_model_deployment\",\n",
    "    #     machine_type=\"n1-standard-2\",\n",
    "    # )\n",
    "    # print(f\"Model deployed to endpoint: {endpoint.resource_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"batch_processing\", description=\"Pipeline responsible for batch processing and model training\")\n",
    "def batch_processing_pipeline(current_year: int = 2024, race_id: int = 1):\n",
    "    \n",
    "    load_preprocess_step = load_and_preprocess(\n",
    "        current_year=current_year,\n",
    "        race_id=race_id,\n",
    "    ).set_display_name(\"Load and Preprocess Data\")\n",
    "\n",
    "    train_step = train_model().after(load_preprocess_step).set_display_name('Model training')\n",
    "\n",
    "    deploy_model(trained_model=train_step.outputs[\"trained_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241121185501\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241121185501')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west3/pipelines/runs/batch-processing-20241121185501?project=248863766350\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241121185501 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241121185501 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241121185501\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=batch_processing_pipeline,\n",
    "    package_path=\"batch_processing_pipeline.json\",\n",
    ")\n",
    "\n",
    "aiplatform.init(project=\"bda-gameon-demo\", location=\"europe-west3\")\n",
    "\n",
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name=\"batch_processing_job\",\n",
    "    template_path=\"batch_processing_pipeline.json\",\n",
    "    parameter_values={\n",
    "        \"current_year\": 2024,\n",
    "        \"race_id\": 5,\n",
    "    },\n",
    ")\n",
    "\n",
    "pipeline_job.run(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
