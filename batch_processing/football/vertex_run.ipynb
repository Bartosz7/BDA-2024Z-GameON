{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import (\n",
    "    component, \n",
    "    Output,\n",
    "    Input,\n",
    "    Model\n",
    ")\n",
    "\n",
    "from kfp import compiler\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = \"europe-west3-docker.pkg.dev/bda-gameon-demo/vertex/base_football_container:1.0.15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def load_and_preprocess(\n",
    "    gamesweek: int,\n",
    "    competitionId: int,\n",
    "):\n",
    "    import requests\n",
    "    from vertex_utils import (\n",
    "        prepare_df_from_events_api,\n",
    "        prepare_df_from_matches_api,\n",
    "        fetch_events_data,\n",
    "        merge_events_and_matches,\n",
    "        enrich_with_tags_names,\n",
    "        save_historic_to_big_query,\n",
    "        prepare_aggregations,\n",
    "    )\n",
    "    \n",
    "    API_BASE_URL = \"https://big-data-project-api-248863766350.europe-west3.run.app\"\n",
    "\n",
    "    api_match_url = f\"{API_BASE_URL}/matches?gameweek={gamesweek}&competitionId={competitionId}\"\n",
    "\n",
    "    print(f\"Fetching match info for competition: {competitionId} and gameweek: {gamesweek}...\")\n",
    "    response_matches = requests.get(api_match_url)\n",
    "\n",
    "    if response_matches.status_code != 200:\n",
    "        raise Exception(f\"API call failed with status code {response_matches.status_code}: {response_matches.text}\")\n",
    "\n",
    "    matches_data = response_matches.json()\n",
    "\n",
    "    if \"matches\" not in matches_data:\n",
    "        raise ValueError(\"Invalid matches data format received from API.\")\n",
    "\n",
    "    print(f\"Gathering match info for competition: {competitionId} and gamesweek: {gamesweek}...\")\n",
    "    matches_df = prepare_df_from_matches_api(matches_data)\n",
    "\n",
    "    print(f\"Fetching events data for competition: {competitionId} and gameweek: {gamesweek}...\")\n",
    "    events_data = fetch_events_data(matches_df, API_BASE_URL)\n",
    "\n",
    "    print(f\"Preparing events DataFrame for competition: {competitionId} and gameweek: {gamesweek}...\")\n",
    "    events_df = prepare_df_from_events_api(events_data)\n",
    "\n",
    "    print(\"Merging events and match data...\")\n",
    "    df = merge_events_and_matches(events_df, matches_df)\n",
    "\n",
    "    print(\"Enriching with tags names...\")\n",
    "    df = enrich_with_tags_names(df)\n",
    "\n",
    "    print(\"Preparing aggregations...\")\n",
    "    aggregations = prepare_aggregations(df)\n",
    "\n",
    "    print(\"Saving aggregations to BigQuery...\")\n",
    "    save_historic_to_big_query(aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=BASE_IMAGE)\n",
    "def train_model():\n",
    "    from google.cloud import bigquery\n",
    "    import logging\n",
    "\n",
    "    model_option_list = \"\"\"\n",
    "        model_type='RANDOM_FOREST_CLASSIFIER',\n",
    "        input_label_cols=['result'],\n",
    "        num_parallel_tree=100,\n",
    "        max_tree_depth=10,\n",
    "        colsample_bynode=0.3,\n",
    "        subsample=0.3,\n",
    "        data_split_method='RANDOM',\n",
    "        data_split_eval_fraction=0.3,\n",
    "        enable_global_explain=True\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    query = f\"\"\"\n",
    "        CREATE OR REPLACE MODEL football.random_forest_classifier\n",
    "        OPTIONS({model_option_list})\n",
    "        AS\n",
    "        SELECT\n",
    "            result,\n",
    "            home_goals,\n",
    "            away_goals,\n",
    "            home_passes,\n",
    "            away_passes,\n",
    "            home_fouls,\n",
    "            away_fouls,\n",
    "            home_shots,\n",
    "            away_shots,\n",
    "            home_accurate_shots,\n",
    "            away_accurate_shots,\n",
    "            home_duels_won,\n",
    "            away_duels_won,\n",
    "            home_possession_time,\n",
    "            away_possession_time,\n",
    "            goals_diff,\n",
    "            passes_diff,\n",
    "            fouls_diff,\n",
    "            shots_diff,\n",
    "            accurate_shots_diff,\n",
    "            duels_won_diff,\n",
    "            possession_time_diff\n",
    "        FROM\n",
    "            `bda-gameon-demo.football.historic_aggregations`\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Initializing BigQuery client...\")\n",
    "        client = bigquery.Client(project=\"bda-gameon-demo\")\n",
    "        logging.info(\"Running query:\\n%s\", query)\n",
    "        query_job = client.query(query)\n",
    "        query_job.result()  # Wait for the query to complete\n",
    "        logging.info(\"Query completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(\"Failed to execute query: %s\", str(e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"batch_processing\", description=\"Pipeline responsible for batch processing and model training\")\n",
    "def batch_processing_pipeline(\n",
    "    gamesweek: int = 2,\n",
    "    competitionId: int = 524,\n",
    "):\n",
    "    load_and_preprocess_step = load_and_preprocess(\n",
    "        gamesweek=gamesweek,\n",
    "        competitionId=competitionId\n",
    "    ).set_display_name(\"Load and Preprocess\")\n",
    "\n",
    "    train_model_step = train_model().after(load_and_preprocess_step).set_display_name(\"Train Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west3/pipelines/runs/batch-processing-20250117-140933?project=248863766350\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20250117-140933\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=batch_processing_pipeline,\n",
    "    package_path=\"batch_processing_pipeline.json\",\n",
    ")\n",
    "\n",
    "aiplatform.init(project=\"bda-gameon-demo\", location=\"europe-west3\")\n",
    "\n",
    "from datetime import datetime\n",
    "job_name = f\"batch-processing-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name=\"batch_processing_job\",\n",
    "    template_path=\"batch_processing_pipeline.json\",\n",
    "    job_id=job_name,\n",
    "    parameter_values={\n",
    "        \"gamesweek\": 2,\n",
    "        \"competitionId\": 524,\n",
    "    },\n",
    "    enable_caching=False\n",
    ")\n",
    "\n",
    "pipeline_job.run(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
