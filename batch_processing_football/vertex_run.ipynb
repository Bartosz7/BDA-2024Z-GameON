{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.dsl import (\n",
    "    component, \n",
    "    Output,\n",
    "    Input,\n",
    "    Model\n",
    ")\n",
    "\n",
    "from kfp import compiler\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = \"europe-west3-docker.pkg.dev/bda-gameon-demo/vertex/base_football_container:1.0.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def load_and_preprocess(\n",
    "    gamesweek: int,\n",
    "    competitionId: int,\n",
    "):\n",
    "    import requests\n",
    "    from vertex_utils import (\n",
    "        prepare_df_from_events_api,\n",
    "        prepare_df_from_matches_api,\n",
    "        fetch_events_data,\n",
    "        merge_events_and_matches,\n",
    "        enrich_with_tags_names,\n",
    "        save_historic_to_big_query,\n",
    "        prepare_aggregations,\n",
    "    )\n",
    "    \n",
    "    API_BASE_URL = \"https://big-data-project-api-248863766350.europe-west3.run.app\"\n",
    "\n",
    "    # Fetch matches for the given gameweek and competitionId\n",
    "    api_match_url = f\"{API_BASE_URL}/matches?gameweek={gamesweek}&competitionId={competitionId}\"\n",
    "\n",
    "    print(f\"Fetching match info for competition: {competitionId} and gameweek: {gamesweek}...\")\n",
    "    response_matches = requests.get(api_match_url)\n",
    "\n",
    "    if response_matches.status_code != 200:\n",
    "        raise Exception(f\"API call failed with status code {response_matches.status_code}: {response_matches.text}\")\n",
    "\n",
    "    matches_data = response_matches.json()\n",
    "\n",
    "    if \"matches\" not in matches_data:\n",
    "        raise ValueError(\"Invalid matches data format received from API.\")\n",
    "\n",
    "    print(f\"Gathering match info for competition: {competitionId} and gamesweek: {gamesweek}...\")\n",
    "    matches_df = prepare_df_from_matches_api(matches_data)\n",
    "\n",
    "    print(f\"Fetching events data for competition: {competitionId} and gameweek: {gamesweek}...\")\n",
    "    events_data = fetch_events_data(matches_df, API_BASE_URL)\n",
    "\n",
    "    # Convert events data to a DataFrame\n",
    "    print(f\"Preparing events DataFrame for competition: {competitionId} and gameweek: {gamesweek}...\")\n",
    "    events_df = prepare_df_from_events_api(events_data)\n",
    "\n",
    "    print(\"Merging events and match data...\")\n",
    "    df = merge_events_and_matches(events_df, matches_df)\n",
    "\n",
    "    print(\"Enriching with tags names...\")\n",
    "    df = enrich_with_tags_names(df)\n",
    "\n",
    "    print(\"Preparing aggregations...\")\n",
    "    aggregations = prepare_aggregations(df)\n",
    "\n",
    "    print(\"Saving aggregations to BigQuery...\")\n",
    "    save_historic_to_big_query(aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=BASE_IMAGE\n",
    ")\n",
    "def train_model():\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    query = \"\"\"    \n",
    "        CREATE OR REPLACE MODEL football.lightgbm_model\n",
    "        OPTIONS(model_type='BOOSTED_TREE_CLASSIFIER',\n",
    "                input_label_cols=['label'],\n",
    "                budget_hours=1)\n",
    "        AS\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            `bda-gameon-demo.football.historic_aggregations`\n",
    "    \"\"\"\n",
    "\n",
    "    client = bigquery.Client(project=\"bda-gameon-demo\")\n",
    "    client.query(query).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"batch_processing\", description=\"Pipeline responsible for batch processing and model training\")\n",
    "def batch_processing_pipeline(\n",
    "    gamesweek: int = 1,\n",
    "    competitionId: int = 364,\n",
    "):\n",
    "    load_and_preprocess_step = load_and_preprocess(\n",
    "        gamesweek=gamesweek,\n",
    "        competitionId=competitionId\n",
    "    ).set_display_name(\"Load and Preprocess\")\n",
    "\n",
    "    train_model_step = train_model().after(load_and_preprocess_step).set_display_name(\"Train Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west3/pipelines/runs/batch-processing-20241124123214?project=248863766350\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/248863766350/locations/europe-west3/pipelineJobs/batch-processing-20241124123214 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \" The DAG failed because some tasks failed. The failed tasks are: [train-model].; Job (project_id = bda-gameon-demo, job_id = 7713058675685851136) is failed due to the above error.; Failed to handle the job: {project_number = 248863766350, job_id = 7713058675685851136}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 17\u001b[0m\n\u001b[1;32m      6\u001b[0m aiplatform\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbda-gameon-demo\u001b[39m\u001b[38;5;124m\"\u001b[39m, location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meurope-west3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m pipeline_job \u001b[38;5;241m=\u001b[39m aiplatform\u001b[38;5;241m.\u001b[39mPipelineJob(\n\u001b[1;32m      9\u001b[0m     display_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_processing_job\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     template_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_processing_pipeline.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     },\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m \u001b[43mpipeline_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py:334\u001b[0m, in \u001b[0;36mPipelineJob.run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout, enable_preflight_validations)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run this configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m        Optional. Whether to enable preflight validations for the PipelineJob.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    332\u001b[0m network \u001b[38;5;241m=\u001b[39m network \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mnetwork\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mservice_account\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mservice_account\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreserved_ip_ranges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreserved_ip_ranges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_preflight_validations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_preflight_validations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/google/cloud/aiplatform/base.py:863\u001b[0m, in \u001b[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    862\u001b[0m         VertexAiResourceNounWithFutureManager\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m internal_callbacks \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py:382\u001b[0m, in \u001b[0;36mPipelineJob._run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout, enable_preflight_validations)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to ensure network synchronization and to run\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03mthe configured PipelineJob and monitor the job until completion.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m        Optional. Whether to enable preflight validations for the PipelineJob.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    375\u001b[0m     service_account\u001b[38;5;241m=\u001b[39mservice_account,\n\u001b[1;32m    376\u001b[0m     network\u001b[38;5;241m=\u001b[39mnetwork,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m     enable_preflight_validations\u001b[38;5;241m=\u001b[39menable_preflight_validations,\n\u001b[1;32m    380\u001b[0m )\n\u001b[0;32m--> 382\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# AutoSxS view model evaluations\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m details \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask_details:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py:793\u001b[0m, in \u001b[0;36mPipelineJob._block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Error is only populated when the job state is\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;66;03m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01min\u001b[39;00m _PIPELINE_ERROR_STATES:\n\u001b[0;32m--> 793\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob failed with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource\u001b[38;5;241m.\u001b[39merror)\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    795\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mlog_action_completed_against_resource(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \" The DAG failed because some tasks failed. The failed tasks are: [train-model].; Job (project_id = bda-gameon-demo, job_id = 7713058675685851136) is failed due to the above error.; Failed to handle the job: {project_number = 248863766350, job_id = 7713058675685851136}\"\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=batch_processing_pipeline,\n",
    "    package_path=\"batch_processing_pipeline.json\",\n",
    ")\n",
    "\n",
    "aiplatform.init(project=\"bda-gameon-demo\", location=\"europe-west3\")\n",
    "\n",
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name=\"batch_processing_job\",\n",
    "    template_path=\"batch_processing_pipeline.json\",\n",
    "    parameter_values={\n",
    "        \"gamesweek\": 1,\n",
    "        \"competitionId\": 364,\n",
    "    },\n",
    ")\n",
    "\n",
    "pipeline_job.run(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
